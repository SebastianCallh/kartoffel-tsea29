\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english, swedish]{babel}

\usepackage{cite}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{float}
\usepackage{textcomp}
\usepackage{listings}
\usepackage{color}
 
\usepackage[top=1.5in,bottom=1in,right=1.5in,left=1.5in,headheight=65pt]{geometry}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\usepackage[yyyymmdd]{datetime}
\renewcommand{\dateseparator}{-}

\usepackage{graphicx}
\graphicspath{ {images/} }

%For headers & footers
\usepackage{fancyhdr}
\usepackage{pdfpages}
%\setlength{\headheight}{110pt} 
\pagestyle{fancy}
\lhead{\includegraphics[scale=0.2]{Logo}}
\chead{Kartrobot}
\rhead{\today}

\lfoot{Konstruktion med mikrodatorer}
\rfoot{Grupp 3}

\usepackage{titlesec}

\setcounter{secnumdepth}{4}

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}


\title{Teknisk dokumentation för kartrobot}
\author{Patrik Sletmo}
\date{\today}

\selectlanguage{swedish}

\begin{document}

\thispagestyle{empty}

{
\sffamily
\centering
\large


{\huge 
Teknisk dokumentation för kartrobot
}

{\large
Patrik Sletmo
}

{\large
Version 1.0
}

\vspace{3.5cm}

Status
\begin{table}[H]
\centering
\begin{tabular}{ | c | c | c | }
\hline
STATUS & Patrik Sletmo & 2016-12-DD \\
\hline
\end{tabular}
\end{table}


\begin{center}
\includegraphics[scale=0.065]{robot_cover_photo}
\end{center}
}

\clearpage

\vspace*{\fill}
{
\sffamily
\centering
\large


{\huge
Projektidentitet
}

{\large
Grupp 3, 16/HT, KarToffel \\ Linköpings tekniska högskola, ISY
}

\vspace{0.5cm}

\begin{table}[H]
\centering
\begin{tabular}{ | c | c | c | c |}
\hline
Namn & Ansvar & Telefon & E-post \\
\hline
Patrik Sletmo & Projektledare & 070 783 57 61 & patsl736@student.liu.se \\
\hline
Rebecca Lindblom & Utvecklare & 073 436 40 79 & rebli156@student.liu.se \\
\hline
Matildha Sjöstedt & Utvecklare & 070 515 84 11 & matsj696@student.liu.se \\
\hline
Sebastian Callh & Utvecklare & 073 820 46 64 & sebca553@student.liu.se \\
\hline
Anton Dalgren & Utvecklare & 076 836 51 56 & antda685@student.liu.se \\
\hline
Matilda Dahlström & Utvecklare & 070 636 33 52 & matda715@student.liu.se \\
\hline
\end{tabular}
\end{table}
}

\begin{center}
\textbf{Hemsida}: https://github.com/SebastianCallh/kartoffel-tsea29
\end{center}

\begin{center}
\textbf{Kund}: Mattias Krysander, 013 - 28 2198 , matkr@isy.liu.se
\end{center}

\begin{center}
\textbf{Kursansvarig}: Tomas Svensson, 3B 528, +46 (0)13 28 1368, tomas.svensson@liu.se \\
\textbf{Handledare}: Anders Nilsson, 3B 512, +46 (0)13 28 2635, anders.p.nilsson@liu.se
\end{center}
\vspace*{\fill}
\clearpage

\renewcommand*\contentsname{Innehållsförteckning}
\tableofcontents
\clearpage


{
\sffamily
\centering
\large


{\huge 
Dokumenthistorik \\
}
\begin{table}[H]
\centering
\begin{tabular}{ | c | c | c | c | c |} 
\hline
\textbf{Version} & \textbf{Datum} & \textbf{Utförda ändringar} & \textbf{Utförd av } & \textbf{Granskad} \\
\hline
VERSION & 2016-12-DD & Första version & Grupp 3 & Patrik Sletmo \\
\hline

\end{tabular}
\end{table}
}

\clearpage
\section{Inledning}
Systemet beskrivet i det här dokumentet är en kartläggningsrobot som dels kan fjärrstyras och dels släppas in i ett rum och autonomt söka av det för att sedan återvända till ingången.
\subsection{Bakgrund}
Som en del av utbildningen till civilingenjör i datateknik på Tekniska högskolan vid Linköpings universitet har denna projektgrupp i kursen Konstruktion med mikrodatorer (TSEA29) arbetat mot beställaren Mattias Krysander för att tillverka en robot vars syfte är att kartlägga en sluten bana. Den färdiga produkten tävlar mot andra gruppers robotar och redovisas i samband med kursens avslutande.

\subsection{Syfte}
Det här dokumentet skall ge en ingående beskrivning av kartrobot-systemet från ett tekniskt perspektiv. Dokumentet ska fungera som konstruktionsunderlag för någon som vill bygga en kopia av den robot som beskrivs. Det ska från instruktioner i dokumentet även vara möjligt att underhålla och felsöka både mjuk- och hårdvaran i systemet.

\clearpage
\section{Produkten}
%En bild på produkten och en beskrivning av hur den fungerar. Beskriv vad den används till.

Systemet består av en fyrhjulig robot samt en mjukvaruklient som kommunicerar med varandra via Bluetooth. Systemets syfte är att roboten ska kunna kartlägga sin omgivning helt autonomt och förmedla kartläggningen till mjukvaruklienten. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.1]{robot_irl}
\caption{En bild på roboten.}
\label{fig:robot_bild}
\end{figure}
\ \\
För att utföra kartläggandet så är roboten utrustad med diverse IR-sensorer, en lasersensor och ett gyroskop för att kunna navigera och mäta avstånd. Se figur~\ref{fig:robot_bild} för en bild på konstruktionen.

\begin{figure}[H]
\centering
\includegraphics[scale=0.55]{client_interface}
\caption{En bild på mjukvaruklienten.}
\label{fig:klient_bild}
\end{figure}
\ \\
Mjukvaruklienten renderar med hjälp av data från dess Bluetooth-anslutning kartläggningen i realtid och har ett gränssnitt för att kunna fjärrstyra roboten. Se figur~\ref{fig:klient_bild} för en bild på mjukvaruklientens gränssnitt.

\clearpage
\section{Teori}
% Beskrivning av regleralgoritmer mm.
För att lyckas kartlägga en bana använder sig systemet av en rad olika algoritmer och tekniker som behandlar problemet att läsa in data från omgivningen, applicera det datat på kartläggningsproblemet, samt att uttrycka resultatet tillbaka till den fysiska verkligheten.

\subsection{Navigering}
\label{sec:navigering}
Navigeringslogiken implementeras som en tillståndsmaskin vars transitioner styrs av indata från robotens sensorer. Den antar att omgivningen följer banspecifikationen i bilaga~\ref{sec:banspec}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{navigator_flowchart}
\caption{Ett flödesdiagram på navigatorns tillstånd.}
\label{fig:navigator_flowchart}
\end{figure}
\ \\
Efter en kort uppvärmningsperiod för att hinna läsa in alla sensorer så börjar roboten följa väggen på sin högra sida och håller ett lämplig avstånd till den med hjälp av en modifierad PID-reglering (se avsnitt~\ref{sec:reglering}). Om roboten upptäcker att väggen på höger sida tar slut så innebär det att väggen har svängt av bort från roboten och att den behöver göra en yttersväng till höger för att följa efter. Skulle roboten upptäcka en vägg framför sig betyder det istället att rummet svängt av till vänster, och att roboten behöver göra en innersväng åt vänster. En återvändsgränd består ur robotens perspektiv av två stycken innersvängar till vänster. Ett flödesdiagram över robotens navigeringstillstånd kan ses i figur~\ref{fig:navigator_flowchart}, vilket är all logik som behövs för att den ska kunna följa en vägg. Logiken hanterar yttersväng åt höger, innersväng åt vänster och även återvändsgränder.

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{navigation_outer_turn}
\caption{En illustration på hur roboten hanterar en yttersväng.}
\label{fig:navigation_outer_turn}
\end{figure}
\ \\
\newline
Det första momentet som roboten behöver kunna genomföra är en yttersväng till höger, vilket illustreras i figur~\ref{fig:navigation_outer_turn}. För att detektera en sväng så använder den sina två IR-sensorer monterade fram respektive bak på höger sida. När den första IR-sensorn inte längre detekterar en vägg går den in i ett läge som förbjuder vänstersvängar, och när den bakre gör samma sak utförst en rotation 90 grader åt höger.

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{navigation_inner_turn}
\caption{En illustration på hur roboten hanterar en innersväng.}
\label{fig:navigation_inner_turn}
\end{figure}
\ \\
\newline
För att utföra en innersväng använder sig roboten av lasersensorn monterad framtill och mäter avståndet till väggen. När avståndet underskrider ett visst tröskelvärde så utför roboten en rotation 90 grader till vänster. Sekvensen illustreras i figur~\ref{fig:navigation_inner_turn}. Värt att notera är att yttersväng till höger tar prioritetet över att göra en innersväng åt vänster. Det vill säga att även om lasersensorns mätvärde underskrider tröskelvärdet så kommer det att ignoreras ifall robotens främre högra IR-sensor meddelar att den är på väg mot en högersväng.

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{navigation_dead_end}
\caption{En illustration på hur roboten hanterar en återvändsgränd.}
\label{fig:navigation_dead_end}
\end{figure}
\ \\
\newline
När roboten tar sig förbi en återvändsgränd faller den i själva verket in i samma rutin som när den utför en innersväng åt vänster upprepat två gånger. Roboten roterar när den närmar sig slutet på återvändsgränden, och direkt efter rotationen upptäcks en vägg framför den och den roterar ytterligare 90 grader för att sedan fortsätta ut ur återvändsgränden. En illustration ses i figur~\ref{fig:navigation_dead_end}.

\subsection{Kartläggning}
\subsubsection{Positionsbestämning}
\label{sec:position}
Under kartläggningen av rummet så räknar roboten sektioner som den har passerat och utnyttjar det för att bestämma sina koordinater när en sektion har passerats. Robotens startkoordinater är alltid i origo och startriktiningen är alltid ``norrut'', alltså positivt längs Y-axeln. När roboten enligt navigeringsalgoritmen i avsnitt~\ref{sec:navigering} bestämmer sig för att ta en sväng och rotera så kommer kartläggningen att spara den nuvarande positionen. Genom att ta skillnaden mellan högsta och lägsta mätvärdet dividerat med storleken på en ruta fås antalet rutor som roboten förflyttat sig. Positionsbestämnigen är även den baserad på en tillståndsmaskin. Den är baserad på två tillstånd, väntar och mäter; där väntar är det tillstånd som roboten befinner sig i när den gör en 90 graders rotation. Därefter går roboten in i tillståndet mäter där en ny sektion initieras och mätdata sparas varje varv i huvudloopen.\newline \newline
Under positionsbestämningen så kommer roboten att hålla utkik efter väggar på vänstersidan för att kunna lokalisera eventuella väggar på en köksö. Så fort roboten ser något på vänstersidan så kommer den att säga att just denna koordinat kan vara en köksö så länge den inte redan har passerats. Om roboten under första varvet åker förbi en koordinat som kan vara en köksö kommer den att tas bort som eventuell köksö.

\subsubsection{Bestämning av köksö}
När roboten har åkt ett varv längs ytterkanterna kommer den att gå in i ett läge där den letar efter köksön. Då kommer den att kolla i listan över potentiella köksöar och hitta minst en koordinat som representerar en köksö. När roboten har transporterat sig till en koordinat i den här listan kommer den att ta en vänstersväng och förflytta sig runt ön. Detta sker på samma sätt som beskrivs ovanför i avsnitt~\ref{sec:position}. När ett varv har passerats återvänder roboten till garaget genom att slutföra varvet. 


\subsection{Reglering}
\label{sec:reglering}
Roboten reglerar längs en vägg på sin högra sida med hjälp av två IR-sensorer, en vid robotens främre del och en vid robotens bakre del. Ett önskat värde är bestämt som det avstånd som roboten ska hålla ifrån väggen den reglerar emot. Med hjälp av det önskade värdet tillsammans med värdena ifrån de två IR-sensorerna räknas ett distansfel ut. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{Reglering}
\caption{En illustration över hur roboten reglerar.}
\label{fig:reglering}
\end{figure}
\ \\
\newline
Distansfelet räknas ut genom att dra bort främre IR-sensorns värde ifrån det önskade avståndet. Sedan läggs ett värde proportionellt mot differensen mellan bakre och främre sensorn till för att efterlikna det verkliga avståndet från väggen (se figur~\ref{fig:reglering}). Detta då värdet ifrån IR-sensorerna ökar mer än det verkliga värdet desto mer vinklad ifrån väggen roboten står.\newline\newline
Med hjälp av distansfelet och differensen utförs en enklare PID-reglering som istället för I- och D-delen använder sig av differensen och returnerar ett regleringsvärde $u$.
\begin{equation}
u[n] = Kp * e[n] + Ka * d
\label{eq:reglering}
\end{equation}  
Regleringsvärdet räknas ut enligt (\ref{eq:reglering}) där $Kp$ och $Ka$ är konstanter, $e[n]$ är distansfelet vid tid $n$, och $d$ är differensen mellan värdena på den bakre och främre IR-sensorn. Regleringsvärdet (som ges av (\ref{eq:reglering})) adderas respektive subtraheras sedan på en standard-hastighet och skickas till de båda hjulparen för att räta upp roboten och få den att följa väggen och hålla ett önskat avstånd. 

\subsection{Kommunikation}
Systemet byggs upp av ett antal separata moduler som behöver samarbeta för att utföra robotens funktion då dess unika funktioner är alldeles för specifika. Kommunikationen som möjliggör detta samarbete sker både via Bluetooth och I2C beroende på modulernas placering i systemet. Då det kan bli förvirrande att hantera dataflödet på två olika protokoll ligger det ett abstraktionslager som kallas EventBus ovanpå dessa överföringsmedier. Detta abstraktionslager samt de underliggande implementationerna beskrivs mer ingående i följande delavsnitt. 

\subsubsection{EventBus}
\label{sec:eventbus}
För att underlätta programmering av logikenheten använder sig systemet av en distribuerad eventbuss kallad EventBus som tillhandahåller funktioner för att skicka data till en annan enhet på bussen och för att lyssna på mottagna meddelanden.

\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{EventBus}
\caption{Översikt över eventbussens möjliga kommunikationsriktningar}
\label{fig:eventbus_structure}
\end{figure}
\ \\
Eventbussen är delad mellan sensorenheten, styrenheten, huvudenheten samt mjukvaruklienten men eftersom bussen saknar funktionalitet för att delegera data vidare till andra enheter kan data inte skickas direkt från t.ex. sensorenheten till styrenheten, se figur~\ref{fig:eventbus_structure}. Eventbussen saknar fysiskt representation i den mening som t.ex. I2C-bussen har utan är bara en abstraktion som med hjälp av de underliggande kommunikationsmedierna realiserar dess distribuerade funktion.
\newline\newline
Tanken med eventbussen är att programmeraren ska slippa tänka på att ett funktionsanrop exekveras på en annan enhet eller varifrån data kommer, så länge det läggs åtanke på att funktionerna exekveras asynkront. All mottagen data behöver manuellt behandlas i ett periodiskt funktionsanrop innan de ``lyssnande'' funktionsanropen körs. För att få en tydligare och mer deterministisk körning av huvudenhetens program läses all mottagen data in i början av varje upprepning av huvudloopen. Data ut från huvudenheten skickas till skillnad från inläsningen direkt när anropet sker för att säkerställa att data kommer fram i andra änden så tidigt som möjligt.

\subsubsection{Bluetooth}
För att roboten ska kunna presentera data används Bluetooth för kommunikation med mjukvaruklienten. Kommunikationen är implementerad i Python och biblioteket Pybluez på både server- och klientsidan. Kommunikationen använder sig även av det allmänna gränssnittet EventBus. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{bt-flow-main-unit}
\caption{Flödesschema över Bluetoothkommunikationen i huvudenheten.}
\label{fig:bt-flow-main-unit}
\end{figure}
\ \\
Figur~\ref{fig:bt-flow-main-unit} visar flödet för Bluetoothkommunikationen i huvudenheten. Själva sändningen och mottagningen av data över Bluetooth hanteras av en Bluetoothserver som körs i en egen process skild från huvudprocessen. Servern går igång automatiskt vid start av roboten, och den kontrollerar ständigt om det finns ny data att ta emot respektive ny data att skicka. All hantering av kommandon sker i huvudprocessen, förutom om den tar emot kommandot omstart som hanteras direkt i serverprocessen. Kommandon till huvudenheten samlas i en kö för inkommande data, där EventBus tittar efter och hämtar ny data om det finns. På samma sätt samlas data som ska till mjukvaruklienten i en kö för utgående data, i detta fall postar EventBus i kön och Bluetoothservern hämtar för att skicka. Dessa in- och utköer är implementerade som textfiler, och det gör det möjligt för serverprocessen och huvudprocessen att kommunicera.

\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{bt-flow-software-client}
\caption{Flödesschema över Bluetoothkommunikationen i mjuvaruklienten.}
\label{fig:bt-flow-software-client}
\end{figure}
\ \\
Bluetoothklientens flöde beskrivs i figur~\ref{fig:bt-flow-software-client} och fungerar på samma sätt som servern, med några mindre skillnader. Klienten körs i samma process men olika trådar, och därför behöver inte heller köerna vara implementerade som textfiler.

\subsubsection{I2C}
\label{sec:i2c}
För att kunna kommunicera med olika moduler och sensorer på själva roboten används en I2C-buss som delas mellan huvudenheten, sensorenheten, styrenheten, laser-sensorn samt gyroskopet där huvudenheten agerar master och alla andra enheter slavar. Eftersom kraven som ställs på kommunikationen mellan modulerna förutsätter att data kan skickas i form av anrop räcker inte I2C-bussens protokoll till utan skrivningen och inläsningen till/från adresser behöver utökas med funktionalitet som gör det möjligt att skicka faktiska datapaket.

\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{Flodesschema_i2c}
\caption{Flödesschema över I2C-kommunikationen}
\label{fig:flodesschema_i2c}
\end{figure}
\ \\
Det påliggande protokollet implementerar köer av paket för båda datariktningarna på AVR:erna som pollas och fylls på från huvudenheten. Varje paket innehåller ett antal bytes för dess data där den första byten innehåller paketets id. Eftersom I2C endast tillåter läsning eller skrivning av en enda byte innehåller varje paket on-the-wire också en inledande byte som specificerar dess längd, vilket ger en maxlängd av 255 bytes. När ett paket lästs in läggs det i en intern kö som hanteras av den modulspecifika koden, se figur~\ref{fig:flodesschema_i2c}.
\newline\newline
Alla inkopplade enheter på I2C-bussen använder sig inte av det protokoll som beskrivs ovan utan kommunikation med vissa enheter fungerar på det vanliga sättet genom läsning och skrivning till adresser. Dessa enheter är laser-sensorn samt gyroskopet, som adresseras direkt från huvudenheten istället för att passera via sensorenheten till följd av begränsningar som följer från single-master implementationen. Läsning från dessa sensorer sker periodvis i huvudenhetens programloop och sparas undan så att olika delar av programmet kan komma åt det senaste datat utan att behöva läsa multipla gånger.

\clearpage
\section{Systemet}
% Ett översiktligt blockschema och en beskrivning av hela systemet.
Roboten och den tillhörande mjukvaruklienten utgör hela systemet som från början av projektet designats ur ett modulbaserat perspektiv. Tanken med denna separation är att varje modul inte ska vara ansvarig för fler områden än den behöver och på så sätt öka underhållbarheten i systemet. Eftersom varje modul är inkluderad i systemet med hjälp av det gemensamma gränssnitt EventBus (se avsnitt~\ref{sec:eventbus}) kan en modul återimplementeras utan att kräva omskrivningar i resten av systemet.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{oversikt_systemet}
\caption{En bild på systemets övergripande konstruktion.}
\label{fig:oversikt_systemet}
\end{figure}
\ \\
I figur~\ref{fig:oversikt_systemet} syns systemet i sin helhet med alla enheter och dess respektive anslutningar till huvudenheten. Hierarkin i systemet gör det tydligt vilken enhet som ansvarar för vilka externa komponenter med undantag för lasersensorn och gyroskopet som kommunicerar direkt mot huvudenheten. Anledningen till denna uppdelning är förklarad i avsnitt~\ref{sec:i2c}.

\subsection{Felsökning av mjukvara}
Redan från tidigt stadie i projektet har det legat högt fokus på testbarhet och felsökning. Det finns enkla gränssnitt både in och ut från robotens alla processorer som gör att data kan manipuleras och inspekteras utan att behöva pausa programmet eller spara undan data i filer.

\subsubsection{Felsökning på AVR}
Eftersom AVR:erna i sitt grundutförande inte kan ge någon avancerad utdata finns möjligheten att på roboten koppla varje AVR direkt till en dators USB-port med hjälp av en seriell anslutningskabel. Genom att öppna seriellporten i t.ex. PuTTY (Windows) eller screen (UNIX) kan data skickas fram och tillbaka mellan datorn och mikroprocessorn, se listing~\ref{lst:avr_debug_screen}. I den nuvarande konfigurationen stöds bara möjligheten att skicka data från roboten till datorn men gränssnittet stödjer även den motsatta datariktningen. Implementationen bygger på att ersätta stdout-strömmen vilket möjliggör utskrift till dator med det bekanta gränssnitt definierat i stdio.h, se listing~\ref{lst:avr_debug_example} för ett komplett exempel.
\newline
\begin{lstlisting}[language=sh, label={lst:avr_debug_screen}, caption={Anslutning via screen}]
$ screen /dev/tty.usbserial
\end{lstlisting}

\begin{lstlisting}[language=C, label={lst:avr_debug_example}, caption=Exempel av utskrift]
#include "common/debug.h"

// Initialization, performed during program startup
initialize_uart();
sei();

// Debugging, performed at any point during execution
int measuredValue = 42;
printf("Measured value: %d\n", measuredValue);
\end{lstlisting}

\subsubsection{Felsökning på Huvudenhet}
Huvudenheten består av en Raspberry PI och kör kod skriven i Python, vilket tillsammans ger den utmärkta felsökningsmöjligheter. Enklast är att ansluta sig till huvudenheten med en SSH-uppkoppling över Eduroam men det går även att koppla in tangentbord, mus och skärm direkt till roboten om så önskas. Ifall det trådlösa nätverket är för instabilt går det också att koppla in en ethernet-sladd mellan datorn och roboten. För att ansluta till enheten via SSH så loggar man in med användaren ``pi'' på den IP-adress som visas på robotens display och anger användarens lösenord. Notera att displayens innehåll uppdateras varje minut-omslag och det kan dröja ett par minuter innan roboten kopplar upp sig mot nätverket första gången.

\subsection{Felsökning av hårdvara}
På grund av varierande spänningsnivåer så inträffar det ibland fel i hårdvaran där mjukvaran har svårigheter att korrigera för felet på egen hand. De vanligaste felen och dess lösningar beskrivs i detta avsnitt.

\subsubsection{Låg batterispänning}
I stort sätt alla fel som uppkommer i hårdvaran beror på en för låg batterispänning. Det finns inget sätt att kontrollera robotens batterispänning från mjukvaruklienten eller huvudenhetens terminal utan batteriet måste avmonteras från roboten för att därefter testas med en multimeter. Lättast sättet att undersöka ifall batteriet har för låg spänning är genom att observera robotens beteende. Vanliga symptom är:

\begin{itemize}
    \item Trötta servon
    \item Sena svängar i hörn
    \item Annorlunda reglering
    \item Fel mätvärden
    \item Bruten anslutning över WiFi
\end{itemize}
\ \\
Ifall något av dessa symptom observeras bör batteriet omedelbart bytas mot ett nyladdat för att undvika skador på roboten.

\subsubsection{Felsökning av I2C}
Ibland händer det att I2C-bussen tappar bort någon enhet eller helt enkelt slutar fungera, särskilt vid låga batterinivåer. Det går att verifiera att I2C-bussen fungerar som den ska genom att köra ett kommando från huvudenhetens terminal. Se listning~\ref{lst:i2c_debug} för kommando och förväntad utdata för en hälsosam buss. Om bussen är trasig så kommer huvudenhetens program att sluta fungera och skriva ut ett felmeddelande i loggen. I de flesta fall går det att lösa problemet genom att bryta och sedan slå på spänningsmatningen till roboten men om batterinivån är låg kan batteriet behöva laddas.

\newline
\begin{lstlisting}[language=sh, label={lst:i2c_debug}, caption={Kommando och förväntad utdata för en fungerande I2C-buss}]
$ i2cdetect -y 1
     0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f
00:          -- -- -- -- -- -- -- -- -- -- -- -- --
10: -- -- -- -- -- -- -- -- -- 19 -- -- -- -- 1e --
20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
30: 30 -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
40: 40 -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
60: -- -- 62 -- -- -- -- -- -- -- -- 6b -- -- -- --
70: -- -- -- -- -- -- -- 77
\end{lstlisting}

\clearpage
\section{Modulerna}

\subsection{Huvudenhet}
Huvudenheten realiseras med en Raspberry PI, på vilken operativsystemet Raspbian körs. Den representerar robotens beslutsfattande organ och sköter navigationsbeslut, kartläggning, kommunikation med mjukvaruklienten samt agerar master på robotens I2C-buss.

\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{mjukvarumoduler}
\caption{Ett diagram över logikenhetens mjukvarumoduler.}
\label{fig:mjukvarumoduler}
\end{figure}
\ \\
 Robotens logik är skriven i programmeringsspråket Python och är moduluppbyggd. Vid start injiceras alla beroenden i programets klasser enligt diagramet i figur~\ref{fig:mjukvarumoduler} och en huvudloop startar som uppdaterar relevanta objekt varje iteration. En beskrivning av mjukvarumodulerna finns nedan.

\subsubsection{Navigator}
Navigator-klassen sköter all logik för förflyttning. Givet viss indata från sensorerna fattar den beslut för att klara av uppdraget. Se avsnitt~\ref{sec:navigering} för en beskrivning av navigeringsalgoritmen som används.

\subsubsection{Communicator}
Communicator tar emot begäran från mjukvarumodulen och innehåller all logik för att leverera korrekt svar. Den skickar både vidare styrkommandon till styrenheten samt returnerar begärd data till mjukvaruklienten. 

\subsubsection{Position}
Position hanterar all logik för hur roboten gör för att bestämma sin position på kartan beroende på vilket tillstånd i kartläggningen roboten befinner sig. Se avsnitt~\ref{sec:position} för en utförligare beskrivning av hur positionsbestämningen fungerar. 

\subsubsection{Driver}
Driver innehåller metoder för att utföra standardiserade förflyttningar, t.ex. en inre högersväng eller en yttre vänstersväng. Vid ett anrop till en metod så ges Driver en uppgift som består av en instruktion, en jämförelsefunktion och ett värde till funktionen som Driver använder för att veta när dess uppgift är klar. Till exempel kan en uppgift (i ord) bestå av "vänstersväng, mät i grader, 90", vilket skulle få roboten att svänga vänster, till det att en skillnad i 90 grader uppmäts från gyroskopet. 

\subsubsection{IR}
IR-modulen har en funktion som anropas när sensorenheten har skickat sensordata via I2C-bussen till huvudheten genom att utnyttja designmönstret Observer. De värden som kommer på bussen sparas ner i modulen och kan då användas i andra moduler.
\subsubsection{Laser}
Laser-modulen läser in mätvärden från lasersensorn och översätter dem till Python-heltal som sedan sparas undan en gång per huvudloop. På så sätt kan övriga moduler läsa det sparade värdet, vilket säkerställer att samtliga av robotens moduler agerar på samma lasersensorvärde.

\subsubsection{Gyro}
Gyro-modulen fyller samma funktion som Laser-modulen. Den läser in värden från gyroskopet och sparar värdena som övriga moduler kan läsa ifrån.


\subsubsection{Kopplingsschema}

\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{Huvudenhet_kopplingsschema}
\caption{Kopplingsschema för huvudenheten.}
\label{fig:huvudenhet_kopplingsschema}
\end{figure}
\ \\
Huvudenheten består av en Raspberry Pi 3 och en LCD-display av modellen JM162A. Utöver kopplingen till LCD:n så kopplas två pins till I2C-bussen. Eftersom Raspberry Pi drivs av 3.3 V matspänning och de övriga ATmega-processorerna i roboten drivs av 5 V så behöver bussen nivåskiftas så att de kan kommunicera med varandra, vilket görs med nivåskiftaren BSS138.

\subsubsection{Komponenter}

\begin{table}[H]
\centering
\caption{En tabell över huvudenhetens komponenter.}
\begin{tabular}{ | c | c | }
\hline
\textbf{Komponent} & \textbf{Antal} \\
\hline
Raspberry PI 3 & 1 \\
\hline
JM162A & 1 \\
\hline
\end{tabular}
\end{table}

\subsubsection{Resurser}

\begin{table}[H]
\centering
\caption{En tabell över tillgänglinga portar på huvudenheten.}
\begin{tabular}{ | c | c | c | }
\hline
\textbf{Port} & \textbf{Antal} & \textbf{Används} \\
\hline
GPIO pins & 40 & 12 \\
\hline
\end{tabular}
\end{table}

\subsection{Sensorenhet}
Sensorenheten har i uppgift att läsa in värden från robotens sensorer och rapportera värden till huvudenheten. Den består av fyra IR-sensorer, ett gyroskop, en lasersensor och har sin egna beräkningsenhet, en ATmega 1284, vilket låter den arbeta asynkront från andra enheter. Den ser på så sätt alltid till att ha data tillgänglig närhelst huvudenheten begär den. För IR-sensorerna sker det genom att processorn låter AD-omvandlaren köras för en sensor i taget och sparar sedan undan avståndet i minnet, medan gyroskop och laser håller koll på sina egna värden och är kopplade direkt på I2C-bussen. Huvudenheten kan sedan fråga sensorenheten efter ny IR-mätdata, eller fråga gyroskopet/lasern direkt varpå den får sensordatan levererad över I2C.
\newline\newline
Avläsningarna från IR-sensorerna är analoga, och konverteras till digitalt med hjälp av ATmegans interna AD-omvandlare. För att sedan omvandla mätdatan till en approximation i millimeter används en tabell sparad i ATmegans minne.


\subsubsection{Kopplingsschema}
\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{Sensorenhet_kopplingsschema}
\caption{Kopplingsschema för sensorenheten.}
\label{fig:sensorenhet_kopplingsschema}
\end{figure}
\ \\
Som figur~\ref{fig:sensorenhet_kopplingsschema} visar är IR-sensorerna kopplade till ATmegan via lågpassfilter för att reducera brus. Längst upp i kopplingsschemat ses den gemensamma I2C-bussen, dit gyroskop och laser är anslutna. Notera att EXO3-komponenten är delad mellan sensorenheten och styrenheten trots att den illustreras som separata komponenter i kopplingsschemat.

\subsubsection{Komponenter}

\begin{table}[H]
\centering
\caption{ Tabell över de komponenter som sensorenheten består av. }
\begin{tabular}{ | c | c | c | c |}
\hline
\textbf{Komponent} & \textbf{Antal} \\
\hline
ATmega 1284 & 1 \\
\hline
LIDAR-Lite v2 & 1 \\
\hline
Knapp & 1 \\
\hline
GP2Y0A41SK IR-Sensor & 3 \\
\hline
GP2Y0A21 IR-Sensor & 1 \\
\hline
Adafruit 10-DOF IMU & 1 \\
\hline
EXO3 & 1 (delad) \\
\hline
\end{tabular}
\end{table}

\subsubsection{Resurser}
% Rada upp tillgängliga portar på mikroprocessorn samt hur många som krävs
% Motivera val av mikroprocessor med uppskattning av de resurser som krävs (prestanda, minne, IO)
\begin{table}[H]
\centering
\caption{Tabell över tillgängliga portar på processorn.}
\begin{tabular}{ | c | c | c | c |}
\hline
\textbf{Port} & \textbf{Antal} & \textbf{Krävs} \\
\hline
SDA & 1 & 1 \\
\hline
SCL & 1 & 1 \\
\hline
PCINT & 24 & 1 \\
\hline
A/D & 8 & 4 \\
\hline
USART & 2 & 1 \\
\hline
JTAG & 1 & 1 \\
\hline
CLK & 1 & 1 \\
\hline
\end{tabular}
\end{table}

\subsubsection{Programflöde}

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{sensorenhet_flowchart}
\caption{Ett flödesdiagram över sensorenhetens tillstånd}
\label{fig:sensorenhet_flowchart}
\end{figure}
\ \\
För att kunna tillhandahålla sensordata från IR-sensorerna när huvudenheten ber den om det så läser sensorenheten in data med jämna mellanrum och sparar den lokalt för att sedan skicka datan på kommando från huvudenheten. Om den fått en begäran om sensordata från huvudenheten så tar det prioritet att leverera den över att läsa in ny data. Ett flödesdiagram över dess beteende ses i figur~\ref{fig:sensorenhet_flowchart}.

\subsection{Styrenhet}
Styrenhetens uppgift är att kontrollera robotens förflyttning genom att ge korrekta signaler till dess hjulservon. Hjulen styrs parvis, det vill säga vänster hjulpar styrs med en signal och höger hjulpar med en annan. Hastigheten på hjulen styrs genom pulsbreddsmodulering (PWM, pulse-width modulation) medan hastigheter internt är definerade som heltal. Att hjulen styrs genom PWM innebär att deras hastighet är beroende av vilken pulskvot utsignalen har. Utsignalen växlar mellan hög och låg med vissa intervall, och ju högre kvot av signalen som är hög ju snabbare kommer hjulen att åka. Det är styrenhetens uppgift att översätta heltalshastigheter till korrekt pulskvot.

\subsubsection{Kopplingsschema}
\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{Styrenhet_kopplingsschema}
\caption{Kopplingsschema för styrenheten.}
\label{fig:styrenhet_kopplingsschema}
\end{figure}
\ \\
Styrenheten klockas av en extern EXO3-klocka som säkerställer en synkroniserad klockfrekvens bland robotens processorer, och är kopplad till de två hjulparen som sitter på robotens kropp. Likt sensorenheten så kommunicerar även styrenheten över I2C-bussen.

\subsubsection{Komponenter}

\begin{table}[H]
  \centering
  \caption{Tabell över styrenhetens komponenter.}
  \begin{tabular}{ | c | c |}
    \hline
    \textbf{Komponent} & \textbf{Antal} \\
    \hline
    ATmega 1284 & 1 \\
    \hline
    Terminator (bas för fyrhjulingsrobot) & 1 \\
    \hline
    EXO3 & 1 (delad) \\
    \hline
  \end{tabular}
\end{table}


\subsubsection{Resurser}
\begin{table}[H]
\centering
\caption{Tabell över tillgängliga portar på processorn.}
\begin{tabular}{ | c | c | c | c |}
\hline
\textbf{Port} & \textbf{Antal} & \textbf{Krävs} \\
\hline
SDA & 1 & 1 \\
\hline
SCL & 1 & 1 \\
\hline
PWM & 6 & 2 \\
\hline
USART & 2 & 1 \\
\hline
JTAG & 1 & 1 \\
\hline
CLK & 1 & 1 \\
\hline
\end{tabular}
\end{table}

\subsubsection{Programflöde}

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{styrenhet_flowchart}
\caption{Ett flödesschema över styrenhetens tillstånd}
\label{fig:styrenhet_flowchart}
\end{figure}
\ \\
Styrenheten står hela tiden och väntar på instruktioner från huvudenheten, och så snart den får några utför den dem så snabbt den kan. En instruktion i det här sammamhanget är att sätta nya hastigheter på de båda hjulparen. Ett flödesschema över styrenhetens beteende kan ses i figur~\ref{fig:styrenhet_flowchart}.

\subsection{Mjukvaruklient}
För att kommunicera med roboten används en mjukvaruklient. Programmet har två moduler, en för presentation av data från roboten, och en för fjärrstyrning. Klienten är skriven i Python, och biblioteket Tkinter för det grafiska gränssnittet samt Pybluez och EventBus för Bluetoothkommunikation. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.55]{client_interface}
\caption{Mjukvaruklientens grafiska gränssnitt}
\label{fig:client_interface}
\end{figure}
\ \\
\subsubsection{Presentationsmodul}
När roboten undersöker rummet kommer den att generera flera olika typer av data. Denna data visas av presentationsmodulen. Roboten skickar ingen data självmant, utan får kontinuerligt begäran av presentationsmodulen över Bluetooth. Sensor-, gyro-, servo- och laserdata presenteras till höger i det grafiska gränssnittet, se figur~\ref{fig:client_interface}. I gränssnittet presenteras också robotens IP-adress om den är uppkopplad på ett trådlöst nätverk.

\subsubsection{Fjärrstyrningsmodul}
I det grafiska gränssnittet finns en panel med knappar för att skicka styrkommandon till roboten, se figur~\ref{fig:client_interface}. Dels finns det två knappar för att växla mellan manuellt och autonomnt styrläge, samt knappar med riktningar för att styra i det manuella läget. För styrning kan även följande tangenter på tangentbordet användas:
\begin{itemize}
    \item Q - fram vänster
    \item W eller pil upp - framåt
    \item E - fram höger
    \item A eller pil vänster - rotera vänster
    \item S eller pil ner - bakåt
    \item D eller pil höger - rotera höger
\end{itemize}

\subsubsection{Programflöde}
Presentations- och fjärrstyrningsmodulen har ingen tydlig distinktion i klientens programflöde, utan sker gemensamt i klientens flöde.

\begin{figure}[H]
\centering
\includegraphics[scale=0.55]{software_client_flowchart}
\caption{Flödesschema för mjukvaruklienten}
\label{fig:software_client_flowchart}
\end{figure}
\ \\
Figur~\ref{fig:software_client_flowchart} visar flödesschemat för mjukvaruklienten. Hanteringen för Bluetooth sker i en separat tråd för att det grafiska gränssnittet ska kunna fungera obeorende av väntan på sändning och mottagande av data. Flödet för Bluetoothkommunikationen kan ses i figur~\ref{fig:bt-flow-software-client}. Om användarinput registreras (se siffra 1 i bilden) hanteras detta av callbackfunktioner i GUI:t. Om denna input är styrkommandon som ska skickas till roboten skickas detta vidare till outboundfunktionerna (se siffra 2 i bilden). Vid uppdatering av EventBus (se siffra 3 i bilden), anropas subscriptionfunktioner som hanterar inkommande data. Vid begäran av data (se siffra 4 i bilden) anropas outbound-funktioner som skickar kommandon till roboten via EventBus. Rendering av gränssnittet och uppritning av ny data (se siffra 5 i bilden) sker i GUI:t.

\clearpage
\section{Slutsatser}
% Vilka förbättringar skulle kunna göras?

\subsection{Navigeringsalgoritm}
\label{sec:slutsatser_navigering}
Navigeringsalgoritmen är i nuläget begränsad till att röra sig i ett rutnät och får således bara röra sig i vinklar som är multiplar av 90 grader. Begränsningen beror på att roboten inte har någon bra logik för att bestämma sin position utan att följa en vägg. Om roboten skulle kunna bestämma sin position när den navigerade i godtycklig riktning och på öppna ytor hade den totala sträckan som roboten behövt färdas minskat.

\subsection{Kartläggning}
Robotens kartläggningsalgoritm kartlägger sin omgivning genom att beräkna raksträckor den åkt när den följt en vägg och sparar start- och slut-koordinaterna. Om roboten kunde observera sin omgivning t.ex. med en svepande laser och beräkna var väggar fanns utifrån den datan så skulle den ej behöva färdas längs med alla väggar för att kartlägga dem. Det här förbättringsförslaget går hand i hand med förbättringarna föreslagna i avsnitt~\ref{sec:slutsatser_navigering}.

\clearpage
\section{Referenser}
\begin{itemize}
    \item Pybluez: https://github.com/karulis/pybluez
    \item Tkinter: https://wiki.python.org/moin/TkInter
\end{itemize}

\appendix
%Appendix
%A. Kopplingsschema
%B. Programlistning och eventuell VHDL kod
%C. Övrigt (typ banspec)
\clearpage
\section{Banspecifikation}
\label{sec:banspec}
\includepdf[pages=-]{banspec}

\end{document}
